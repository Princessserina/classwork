Installing package into ‘/home/dave/R/x86_64-pc-linux-gnu-library/3.6’
(as ‘lib’ is unspecified)
Warning message:
package ‘ lubridate’ is not available (for R version 3.6.3) 
Loading script_dir: .
fileName = ../data/pone.0200187.s002_three_features_extrapolated_only_preop_shock_present_FINAL.csv
Number of executions = 100

>>> execution number: 1
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6

When C=0.1, the MCC value is 0.6	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.6
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8734869
ROC AUC 		0.5818182


TOTAL:

 FN =  1  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.438 	 0.913 	 0.852 	 0.955 	 0.400		 0.873		0.582


>>> execution number: 2
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1293152

When C=0.1, the MCC value is -0.1293152	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9280701
ROC AUC 		0.7152778


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.928		0.715


>>> execution number: 3
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1615146

When C=0.1, the MCC value is 0.1615146	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.16151457061745
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8157001
ROC AUC 		0.7142857


TOTAL:

 FN =  1  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.329 	 0.864 	 0.778 	 0.950 	 0.286		 0.816		0.714


>>> execution number: 4
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2327673

When C=0.1, the MCC value is 0.2327673	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.232767270050342
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9538751
ROC AUC 		0.8821429


TOTAL:

 FN =  1  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.467 	 0.884 	 0.815 	 0.950 	 0.429		 0.954		0.882


>>> execution number: 5
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6091096

When C=0.1, the MCC value is 0.6091096	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.609109590101505
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9441207
ROC AUC 		0.53


TOTAL:

 FN =  4  /  25 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  25 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  2 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  2 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.118 	 0.875 	 0.778 	 0.840 	 0.000		 0.944		0.530


>>> execution number: 6
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 8]
9.756%
[class: 1  #elements = 74]
90.244%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8546215
ROC AUC 		0.7352941


TOTAL:

 FN =  0  /  17 	 (truth == 1) & (prediction < threshold)
 TP =  17  /  17 	 (truth == 1) & (prediction >= threshold)

 FP =  10  /  10 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  10 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.773 	 0.630 	 1.000 	 0.000		 0.855		0.735


>>> execution number: 7
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1005038

When C=0.1, the MCC value is -0.1005038	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9519959
ROC AUC 		0.8492063


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.952		0.849


>>> execution number: 8
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2533333

When C=0.1, the MCC value is 0.2533333	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.253333333333333
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9332451
ROC AUC 		0.7608696


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.933		0.761


>>> execution number: 9
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1399793

When C=0.1, the MCC value is 0.1399793	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.139979294535123
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9569377
ROC AUC 		0.8611111


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.367 	 0.894 	 0.815 	 1.000 	 0.167		 0.957		0.861


>>> execution number: 10
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3685139

When C=0.1, the MCC value is 0.3685139	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.368513865595044
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8893772
ROC AUC 		0.5108696


TOTAL:

 FN =  2  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.184 	 0.894 	 0.815 	 0.913 	 0.250		 0.889		0.511


>>> execution number: 11
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.07856742

When C=0.1, the MCC value is -0.07856742	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8425673
ROC AUC 		0.375


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.843		0.375


>>> execution number: 12
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.5555556

When C=0.1, the MCC value is 0.5555556	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.555555555555556
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9782091
ROC AUC 		0.8695652


TOTAL:

 FN =  2  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.184 	 0.894 	 0.815 	 0.913 	 0.250		 0.978		0.870


>>> execution number: 13
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.5922201

When C=0.1, the MCC value is 0.5922201	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.592220092263982
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.6464924
ROC AUC 		0.2785714


TOTAL:

 FN =  7  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  13  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.199 	 0.667 	 0.519 	 0.650 	 0.143		 0.646		0.279


>>> execution number: 14
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3426241

When C=0.1, the MCC value is 0.3426241	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.342624144432096
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7837672
ROC AUC 		0.5119048


TOTAL:

 FN =  2  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.279 	 0.864 	 0.778 	 0.905 	 0.333		 0.784		0.512


>>> execution number: 15
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.7071068

When C=0.1, the MCC value is 0.7071068	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.707106781186548
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9571761
ROC AUC 		0.75


TOTAL:

 FN =  2  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.516 	 0.936 	 0.889 	 0.917 	 0.667		 0.957		0.750


>>> execution number: 16
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.09607689

When C=0.1, the MCC value is -0.09607689	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9116735
ROC AUC 		0.7173913


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.920 	 0.852 	 1.000 	 0.000		 0.912		0.717


>>> execution number: 17
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9050268
ROC AUC 		0.6086957


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.920 	 0.852 	 1.000 	 0.000		 0.905		0.609


>>> execution number: 18
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1809068

When C=0.1, the MCC value is -0.1809068	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9604548
ROC AUC 		0.7222222


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.960		0.722


>>> execution number: 19
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 19]
23.171%
[class: 1  #elements = 63]
76.829%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.07692308

When C=0.1, the MCC value is -0.07692308	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9360766
ROC AUC 		0.5972222


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.936		0.597


>>> execution number: 20
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6091096

When C=0.1, the MCC value is 0.6091096	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.609109590101505
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.6856339
ROC AUC 		0.4714286


TOTAL:

 FN =  1  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.329 	 0.864 	 0.778 	 0.950 	 0.286		 0.686		0.471


>>> execution number: 21
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1399793

When C=0.1, the MCC value is 0.1399793	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.139979294535123
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.738872
ROC AUC 		0.5357143


TOTAL:

 FN =  3  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  17  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.294 	 0.829 	 0.741 	 0.850 	 0.429		 0.739		0.536


>>> execution number: 22
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1212277

When C=0.1, the MCC value is 0.1212277	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.121227722454825
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7497611
ROC AUC 		0.4285714


TOTAL:

 FN =  15  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  6  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.189 	 0.400 	 0.333 	 0.286 	 0.500		 0.750		0.429


>>> execution number: 23
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1132277

When C=0.1, the MCC value is -0.1132277	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7669252
ROC AUC 		0.6714286


TOTAL:

 FN =  0  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  7  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.851 	 0.741 	 1.000 	 0.000		 0.767		0.671


>>> execution number: 24
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2533333

When C=0.1, the MCC value is 0.2533333	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.253333333333333
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9007691
ROC AUC 		0.7


TOTAL:

 FN =  1  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.229 	 0.894 	 0.815 	 0.955 	 0.200		 0.901		0.700


>>> execution number: 25
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 11]
13.415%
[class: 1  #elements = 71]
86.585%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1111111

When C=0.1, the MCC value is -0.1111111	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9406098
ROC AUC 		0.8293651


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.941		0.829


>>> execution number: 26
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3819144

When C=0.1, the MCC value is 0.3819144	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.381914369798501
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.871049
ROC AUC 		0.4836957


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.871		0.484


>>> execution number: 27
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.125

When C=0.1, the MCC value is 0.125	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.125
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8695798
ROC AUC 		0.5978261


TOTAL:

 FN =  3  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.120 	 0.870 	 0.778 	 0.870 	 0.250		 0.870		0.598


>>> execution number: 28
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3685139

When C=0.1, the MCC value is 0.3685139	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.368513865595044
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.988334
ROC AUC 		0.9027778


TOTAL:

 FN =  2  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.250 	 0.917 	 0.852 	 0.917 	 0.333		 0.988		0.903


>>> execution number: 29
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7635449
ROC AUC 		0.531746


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.764		0.532


>>> execution number: 30
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.518545

When C=0.1, the MCC value is 0.518545	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.518544972870135
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8428367
ROC AUC 		0.4184783


TOTAL:

 FN =  4  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.070 	 0.844 	 0.741 	 0.826 	 0.250		 0.843		0.418


>>> execution number: 31
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.5025189

When C=0.1, the MCC value is 0.5025189	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.502518907629606
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9206094
ROC AUC 		0.5


TOTAL:

 FN =  2  /  25 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  25 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  2 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  2 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.080 	 0.920 	 0.852 	 0.920 	 0.000		 0.921		0.500


>>> execution number: 32
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3373495

When C=0.1, the MCC value is 0.3373495	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.337349542469993
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7221713
ROC AUC 		0.2663043


TOTAL:

 FN =  8  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  15  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.074 	 0.732 	 0.593 	 0.652 	 0.250		 0.722		0.266


>>> execution number: 33
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3426241

When C=0.1, the MCC value is 0.3426241	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.342624144432096
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7414484
ROC AUC 		0.1630435


TOTAL:

 FN =  2  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.118 	 0.875 	 0.778 	 0.913 	 0.000		 0.741		0.163


>>> execution number: 34
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4414732

When C=0.1, the MCC value is 0.4414732	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.441473159687696
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8890942
ROC AUC 		0.6727273


TOTAL:

 FN =  3  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.433 	 0.884 	 0.815 	 0.864 	 0.600		 0.889		0.673


>>> execution number: 35
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4166667

When C=0.1, the MCC value is 0.4166667	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.416666666666667
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7898737
ROC AUC 		0.4673913


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.790		0.467


>>> execution number: 36
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2477168

When C=0.1, the MCC value is 0.2477168	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.247716847153431
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8922012
ROC AUC 		0.6195652


TOTAL:

 FN =  4  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.279 	 0.864 	 0.778 	 0.826 	 0.500		 0.892		0.620


>>> execution number: 37
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1885618

When C=0.1, the MCC value is 0.1885618	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.188561808316413
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8375856
ROC AUC 		0.5


TOTAL:

 FN =  4  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.070 	 0.844 	 0.741 	 0.826 	 0.250		 0.838		0.500


>>> execution number: 38
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.518545

When C=0.1, the MCC value is 0.518545	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.518544972870135
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8585631
ROC AUC 		0.6304348


TOTAL:

 FN =  2  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.413 	 0.913 	 0.852 	 0.913 	 0.500		 0.859		0.630


>>> execution number: 39
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 18]
21.951%
[class: 1  #elements = 64]
78.049%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1885618

When C=0.1, the MCC value is 0.1885618	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.188561808316413
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9832957
ROC AUC 		0.875


TOTAL:

 FN =  1  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.625 	 0.958 	 0.926 	 0.958 	 0.667		 0.983		0.875


>>> execution number: 40
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2357023

When C=0.1, the MCC value is 0.2357023	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.235702260395516
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9027151
ROC AUC 		0.5277778


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.555 	 0.960 	 0.926 	 1.000 	 0.333		 0.903		0.528


>>> execution number: 41
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6091096

When C=0.1, the MCC value is 0.6091096	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.609109590101505
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.6726403
ROC AUC 		0.4342105


TOTAL:

 FN =  3  /  19 	 (truth == 1) & (prediction < threshold)
 TP =  16  /  19 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  8 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  8 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.108 	 0.780 	 0.667 	 0.842 	 0.250		 0.673		0.434


>>> execution number: 42
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3685139

When C=0.1, the MCC value is 0.3685139	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.368513865595044
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9730979
ROC AUC 		0.8695652


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.920 	 0.852 	 1.000 	 0.000		 0.973		0.870


>>> execution number: 43
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 9]
10.976%
[class: 1  #elements = 73]
89.024%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1434438

When C=0.1, the MCC value is -0.1434438	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9056415
ROC AUC 		0.6181818


TOTAL:

 FN =  0  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.898 	 0.815 	 1.000 	 0.000		 0.906		0.618


>>> execution number: 44
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2695652

When C=0.1, the MCC value is 0.2695652	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.269565217391304
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8522097
ROC AUC 		0.6547619


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.367 	 0.894 	 0.815 	 1.000 	 0.167		 0.852		0.655


>>> execution number: 45
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2842676

When C=0.1, the MCC value is 0.2842676	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.284267621807481
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9128786
ROC AUC 		0.6847826


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.913		0.685


>>> execution number: 46
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.3447914

When C=0.1, the MCC value is -0.3447914	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7657833
ROC AUC 		0.7716049


TOTAL:

 FN =  0  /  18 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  18 	 (truth == 1) & (prediction >= threshold)

 FP =  9  /  9 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  9 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.800 	 0.667 	 1.000 	 0.000		 0.766		0.772


>>> execution number: 47
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 20]
24.390%
[class: 1  #elements = 62]
75.610%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.06666667

When C=0.1, the MCC value is -0.06666667	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9985484
ROC AUC 		0.9615385


TOTAL:

 FN =  0  /  26 	 (truth == 1) & (prediction < threshold)
 TP =  26  /  26 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  1 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  1 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.981 	 0.963 	 1.000 	 0.000		 0.999		0.962


>>> execution number: 48
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.5948497

When C=0.1, the MCC value is 0.5948497	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.594849690128653
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8118354
ROC AUC 		0.4727273


TOTAL:

 FN =  0  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.898 	 0.815 	 1.000 	 0.000		 0.812		0.473


>>> execution number: 49
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9982991
ROC AUC 		0.9861111


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.998		0.986


>>> execution number: 50
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1885618

When C=0.1, the MCC value is 0.1885618	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.188561808316413
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9083266
ROC AUC 		0.5923913


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.920 	 0.852 	 1.000 	 0.000		 0.908		0.592


>>> execution number: 51
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 10]
12.195%
[class: 1  #elements = 72]
87.805%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3768673

When C=0.1, the MCC value is 0.3768673	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.376867331440716
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7265349
ROC AUC 		0.55


TOTAL:

 FN =  4  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  16  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  4  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.356 	 0.821 	 0.741 	 0.800 	 0.571		 0.727		0.550


>>> execution number: 52
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.09607689

When C=0.1, the MCC value is -0.09607689	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8828957
ROC AUC 		0.7142857


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.883		0.714


>>> execution number: 53
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 18]
21.951%
[class: 1  #elements = 64]
78.049%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4714045

When C=0.1, the MCC value is 0.4714045	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.471404520791032
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9203292
ROC AUC 		0.7045455


TOTAL:

 FN =  2  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.338 	 0.889 	 0.815 	 0.909 	 0.400		 0.920		0.705


>>> execution number: 54
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1615146

When C=0.1, the MCC value is 0.1615146	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.16151457061745
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8782671
ROC AUC 		0.21


TOTAL:

 FN =  5  /  25 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  25 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  2 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  2 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.135 	 0.851 	 0.741 	 0.800 	 0.000		 0.878		0.210


>>> execution number: 55
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4382863

When C=0.1, the MCC value is 0.4382863	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.438286278201907
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9460627
ROC AUC 		0.49


TOTAL:

 FN =  1  /  25 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  25 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  2 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  2 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.055 	 0.941 	 0.889 	 0.960 	 0.000		 0.946		0.490


>>> execution number: 56
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.09607689

When C=0.1, the MCC value is -0.09607689	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.6740171
ROC AUC 		0.6234568


TOTAL:

 FN =  0  /  18 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  18 	 (truth == 1) & (prediction >= threshold)

 FP =  9  /  9 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  9 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.800 	 0.667 	 1.000 	 0.000		 0.674		0.623


>>> execution number: 57
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8778648
ROC AUC 		0.7


TOTAL:

 FN =  0  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.898 	 0.815 	 1.000 	 0.000		 0.878		0.700


>>> execution number: 58
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1601282

When C=0.1, the MCC value is 0.1601282	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.160128153805087
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8779875
ROC AUC 		0.6086957


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.878		0.609


>>> execution number: 59
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6655458

When C=0.1, the MCC value is 0.6655458	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.665545829862154
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7168698
ROC AUC 		0.3454545


TOTAL:

 FN =  4  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.018 	 0.818 	 0.704 	 0.818 	 0.200		 0.717		0.345


>>> execution number: 60
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3685139

When C=0.1, the MCC value is 0.3685139	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.368513865595044
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.945577
ROC AUC 		0.7826087


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.946		0.783


>>> execution number: 61
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 18]
21.951%
[class: 1  #elements = 64]
78.049%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.125

When C=0.1, the MCC value is 0.125	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.125
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9528538
ROC AUC 		0.64


TOTAL:

 FN =  0  /  25 	 (truth == 1) & (prediction < threshold)
 TP =  25  /  25 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  2 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  2 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.693 	 0.980 	 0.963 	 1.000 	 0.500		 0.953		0.640


>>> execution number: 62
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.663325

When C=0.1, the MCC value is 0.663325	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.66332495807108
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7883799
ROC AUC 		0.4636364


TOTAL:

 FN =  4  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.204 	 0.837 	 0.741 	 0.818 	 0.400		 0.788		0.464


>>> execution number: 63
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 18]
21.951%
[class: 1  #elements = 64]
78.049%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.1132277

When C=0.1, the MCC value is -0.1132277	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9784861
ROC AUC 		0.76


TOTAL:

 FN =  0  /  25 	 (truth == 1) & (prediction < threshold)
 TP =  25  /  25 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  2 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  2 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.962 	 0.926 	 1.000 	 0.000		 0.978		0.760


>>> execution number: 64
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.08973032

When C=0.1, the MCC value is -0.08973032	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8671859
ROC AUC 		0.5636364


TOTAL:

 FN =  0  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.898 	 0.815 	 1.000 	 0.000		 0.867		0.564


>>> execution number: 65
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.530791

When C=0.1, the MCC value is 0.530791	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.53079104215763
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7803846
ROC AUC 		0.6642857


TOTAL:

 FN =  2  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.371 	 0.857 	 0.778 	 0.900 	 0.429		 0.780		0.664


>>> execution number: 66
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2110267

When C=0.1, the MCC value is 0.2110267	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.211026726541659
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.969695
ROC AUC 		0.7916667


TOTAL:

 FN =  4  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.378 	 0.889 	 0.815 	 0.833 	 0.667		 0.970		0.792


>>> execution number: 67
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4166667

When C=0.1, the MCC value is 0.4166667	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.416666666666667
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9813059
ROC AUC 		0.8472222


TOTAL:

 FN =  3  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.438 	 0.913 	 0.852 	 0.875 	 0.667		 0.981		0.847


>>> execution number: 68
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9581403
ROC AUC 		0.8373016


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.958		0.837


>>> execution number: 69
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 1

When C=0.1, the MCC value is 1	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=1
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.6943993
ROC AUC 		0.3928571


TOTAL:

 FN =  3  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.204 	 0.837 	 0.741 	 0.857 	 0.333		 0.694		0.393


>>> execution number: 70
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4414732

When C=0.1, the MCC value is 0.4414732	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.441473159687696
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9471327
ROC AUC 		0.6875


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.947		0.688


>>> execution number: 71
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9619476
ROC AUC 		0.8730159


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.962		0.873


>>> execution number: 72
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6793662

When C=0.1, the MCC value is 0.6793662	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.679366220486757
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9050232
ROC AUC 		0.6521739


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.082 	 0.898 	 0.815 	 0.957 	 0.000		 0.905		0.652


>>> execution number: 73
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 10]
12.195%
[class: 1  #elements = 72]
87.805%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3426241

When C=0.1, the MCC value is 0.3426241	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.342624144432096
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8139874
ROC AUC 		0.7323529


TOTAL:

 FN =  2  /  17 	 (truth == 1) & (prediction < threshold)
 TP =  15  /  17 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  10 	 (truth == 0) & (prediction >= threshold)
 TN =  5  /  10 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.421 	 0.811 	 0.741 	 0.882 	 0.500		 0.814		0.732


>>> execution number: 74
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8366264
ROC AUC 		0.5272727


TOTAL:

 FN =  0  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.898 	 0.815 	 1.000 	 0.000		 0.837		0.527


>>> execution number: 75
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8595529
ROC AUC 		0.7142857


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  6  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.875 	 0.778 	 1.000 	 0.000		 0.860		0.714


>>> execution number: 76
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 11]
13.415%
[class: 1  #elements = 71]
86.585%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.518545

When C=0.1, the MCC value is 0.518545	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.518544972870135
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7843728
ROC AUC 		0.4681818


TOTAL:

 FN =  1  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.229 	 0.894 	 0.815 	 0.955 	 0.200		 0.784		0.468


>>> execution number: 77
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.65

When C=0.1, the MCC value is 0.65	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.65
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7886904
ROC AUC 		0.2777778


TOTAL:

 FN =  4  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.147 	 0.851 	 0.741 	 0.833 	 0.000		 0.789		0.278


>>> execution number: 78
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.8928054

When C=0.1, the MCC value is 0.8928054	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.892805381522402
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8484482
ROC AUC 		0.5674603


TOTAL:

 FN =  5  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  16  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.090 	 0.780 	 0.667 	 0.762 	 0.333		 0.848		0.567


>>> execution number: 79
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.6655458

When C=0.1, the MCC value is 0.6655458	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.665545829862154
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7386015
ROC AUC 		0.4325397


TOTAL:

 FN =  4  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  17  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.143 	 0.810 	 0.704 	 0.810 	 0.333		 0.739		0.433


>>> execution number: 80
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1885618

When C=0.1, the MCC value is 0.1885618	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.188561808316413
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9911678
ROC AUC 		0.9305556


TOTAL:

 FN =  1  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.350 	 0.939 	 0.889 	 0.958 	 0.333		 0.991		0.931


>>> execution number: 81
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.09607689

When C=0.1, the MCC value is -0.09607689	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.957223
ROC AUC 		0.8152174


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.920 	 0.852 	 1.000 	 0.000		 0.957		0.815


>>> execution number: 82
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 11]
13.415%
[class: 1  #elements = 71]
86.585%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9238723
ROC AUC 		0.5869565


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.920 	 0.852 	 1.000 	 0.000		 0.924		0.587


>>> execution number: 83
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8966579
ROC AUC 		0.7642857


TOTAL:

 FN =  0  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  7  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.851 	 0.741 	 1.000 	 0.000		 0.897		0.764


>>> execution number: 84
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 10]
12.195%
[class: 1  #elements = 72]
87.805%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.01331205

When C=0.1, the MCC value is 0.01331205	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.0133120510638479
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9078336
ROC AUC 		0.7318182


TOTAL:

 FN =  2  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.509 	 0.909 	 0.852 	 0.909 	 0.600		 0.908		0.732


>>> execution number: 85
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = -0.01623283

When C=0.1, the MCC value is -0.01623283	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8559802
ROC AUC 		0.6863636


TOTAL:

 FN =  0  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.898 	 0.815 	 1.000 	 0.000		 0.856		0.686


>>> execution number: 86
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 18]
21.951%
[class: 1  #elements = 64]
78.049%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9711856
ROC AUC 		0.8194444


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.971		0.819


>>> execution number: 87
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3426241

When C=0.1, the MCC value is 0.3426241	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.342624144432096
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8396757
ROC AUC 		0.6349206


TOTAL:

 FN =  2  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.433 	 0.884 	 0.815 	 0.905 	 0.500		 0.840		0.635


>>> execution number: 88
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2477168

When C=0.1, the MCC value is 0.2477168	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.247716847153431
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8205007
ROC AUC 		0.6681818


TOTAL:

 FN =  1  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.606 	 0.933 	 0.889 	 0.955 	 0.600		 0.821		0.668


>>> execution number: 89
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.1, the MCC value is 0	 (worst possible: -1; best possible: +1)

The best C value is 0.001, corresponding to MCC=0
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.001) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9831163
ROC AUC 		0.875


TOTAL:

 FN =  0  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  24  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.000 	 0.941 	 0.889 	 1.000 	 0.000		 0.983		0.875


>>> execution number: 90
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1885618

When C=0.1, the MCC value is 0.1885618	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.188561808316413
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8652382
ROC AUC 		0.6136364


TOTAL:

 FN =  1  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.438 	 0.913 	 0.852 	 0.955 	 0.400		 0.865		0.614


>>> execution number: 91
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 17]
20.732%
[class: 1  #elements = 65]
79.268%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.2842676

When C=0.1, the MCC value is 0.2842676	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.284267621807481
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9891349
ROC AUC 		0.9166667


TOTAL:

 FN =  1  /  24 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  24 	 (truth == 1) & (prediction >= threshold)

 FP =  1  /  3 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  3 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.625 	 0.958 	 0.926 	 0.958 	 0.667		 0.989		0.917


>>> execution number: 92
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 12]
14.634%
[class: 1  #elements = 70]
85.366%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.4414732

When C=0.1, the MCC value is 0.4414732	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.441473159687696
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8368383
ROC AUC 		0.5785714


TOTAL:

 FN =  3  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  17  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  5  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.153 	 0.810 	 0.704 	 0.850 	 0.286		 0.837		0.579


>>> execution number: 93
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.5130435

When C=0.1, the MCC value is 0.5130435	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.51304347826087
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8458672
ROC AUC 		0.6031746


TOTAL:

 FN =  2  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  19  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  2  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.279 	 0.864 	 0.778 	 0.905 	 0.333		 0.846		0.603


>>> execution number: 94
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3426241

When C=0.1, the MCC value is 0.3426241	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.342624144432096
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.7921846
ROC AUC 		0.3913043


TOTAL:

 FN =  3  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  20  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  4  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  0  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      -0.147 	 0.851 	 0.741 	 0.870 	 0.000		 0.792		0.391


>>> execution number: 95
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1931218

When C=0.1, the MCC value is 0.1931218	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.193121819834107
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8887661
ROC AUC 		0.5978261


TOTAL:

 FN =  0  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  23  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.470 	 0.939 	 0.889 	 1.000 	 0.250		 0.889		0.598


>>> execution number: 96
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.03553345

When C=0.1, the MCC value is 0.03553345	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.0355334527259351
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8188405
ROC AUC 		0.6636364


TOTAL:

 FN =  1  /  22 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  22 	 (truth == 1) & (prediction >= threshold)

 FP =  2  /  5 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  5 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.606 	 0.933 	 0.889 	 0.955 	 0.600		 0.819		0.664


>>> execution number: 97
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 15]
18.293%
[class: 1  #elements = 67]
81.707%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.0761387

When C=0.1, the MCC value is 0.0761387	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.0761386987626881
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9948843
ROC AUC 		0.9673913


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  0  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  4  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.875 	 0.978 	 0.963 	 0.957 	 1.000		 0.995		0.967


>>> execution number: 98
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 13]
15.854%
[class: 1  #elements = 69]
84.146%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.3426241

When C=0.1, the MCC value is 0.3426241	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.342624144432096
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.8943595
ROC AUC 		0.7285714


TOTAL:

 FN =  2  /  20 	 (truth == 1) & (prediction < threshold)
 TP =  18  /  20 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  7 	 (truth == 0) & (prediction >= threshold)
 TN =  4  /  7 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.497 	 0.878 	 0.815 	 0.900 	 0.571		 0.894		0.729


>>> execution number: 99
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 14]
17.073%
[class: 1  #elements = 68]
82.927%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1005038

When C=0.1, the MCC value is 0.1005038	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.100503781525921
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9284631
ROC AUC 		0.7336957


TOTAL:

 FN =  1  /  23 	 (truth == 1) & (prediction < threshold)
 TP =  22  /  23 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  4 	 (truth == 0) & (prediction >= threshold)
 TN =  1  /  4 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.280 	 0.917 	 0.852 	 0.957 	 0.250		 0.928		0.734


>>> execution number: 100
[Dataset size]
number of data instances (rows) = 137 
number of features (columns) = 4 

[Imbalance of this dataset]
[class: 0  #elements = 24]
17.518%
[class: 1  #elements = 113]
82.482%

training_set_perce = 60% 
validation_set_perce = 20% 
test_set_perce = 20% 
[Creating the subsets]
training set BEFORE oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 16]
19.512%
[class: 1  #elements = 66]
80.488%

training set AFTER oversampling:
[Imbalance of this dataset]
[class: 0  #elements = 40]
48.780%
[class: 1  #elements = 42]
51.220%


[Optimization of the hyper-parameter C start]
[Training the SVM model (with C=0.001) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.001, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.01) on training set & applying the SVM model to validation set]

MCC = 0

When C=0.01, the MCC value is 0	 (worst possible: -1; best possible: +1)
[Training the SVM model (with C=0.1) on training set & applying the SVM model to validation set]

MCC = 0.1931218

When C=0.1, the MCC value is 0.1931218	 (worst possible: -1; best possible: +1)

The best C value is 0.1, corresponding to MCC=0.193121819834107
[Optimization end]


 @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ @ 

[Training the SVM model (with the OPTIMIZED hyper-parameter C=0.1) on training set & applying the SVM to the test set]

PR AUC (integral) 	0.9468042
ROC AUC 		0.8452381


TOTAL:

 FN =  0  /  21 	 (truth == 1) & (prediction < threshold)
 TP =  21  /  21 	 (truth == 1) & (prediction >= threshold)

 FP =  3  /  6 	 (truth == 0) & (prediction >= threshold)
 TN =  3  /  6 	 (truth == 0) & (prediction < threshold)



 @@@ Test set @@@ 	 MCC 	 F1_score 	 accuracy 	 TP_rate 	 TN_rate 	 PR AUC 	 ROC AUC
@@@ Test set @@@      0.661 	 0.933 	 0.889 	 1.000 	 0.500		 0.947		0.845




=== final results ===
Number of executions = 100
                 MCC F1_score accuracy TP_rate TN_rate  PR_AUC ROC_AUC
nbr.val      100.000  100.000  100.000 100.000 100.000 100.000 100.000
nbr.null      34.000    0.000    0.000   0.000  42.000   0.000   0.000
nbr.na         0.000    0.000    0.000   0.000   0.000   0.000   0.000
min           -0.199    0.400    0.333   0.286   0.000   0.646   0.163
max            0.875    0.981    0.963   1.000   1.000   0.999   0.986
range          1.074    0.581    0.630   0.714   1.000   0.352   0.823
sum           17.909   88.319   80.630  92.899  22.612  87.328  64.185
median         0.114    0.894    0.815   0.957   0.250   0.889   0.653
mean           0.179    0.883    0.806   0.929   0.226   0.873   0.642
SE.mean        0.023    0.007    0.009   0.010   0.023   0.009   0.018
CI.mean.0.95   0.046    0.014    0.018   0.020   0.046   0.017   0.035
var            0.055    0.005    0.008   0.010   0.055   0.008   0.031
std.dev        0.234    0.072    0.092   0.100   0.234   0.087   0.176
coef.var       1.304    0.082    0.114   0.108   1.034   0.100   0.274


          MCC F1_score accuracy TP_rate TN_rate PR_AUC ROC_AUC
mean   +0.179    0.883    0.806   0.929   0.226  0.873   0.642
std.dev 0.234    0.072    0.092   0.100   0.234  0.087   0.176


=== === === ===

Total execution time: 5.982497 seconds
0 days, 00 hours, 00 minutes, 5.98 seconds

